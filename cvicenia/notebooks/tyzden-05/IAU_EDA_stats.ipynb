{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA s využitím štatistickej analýzy\n",
    "\n",
    "### Asumptions\n",
    "- the data must be randomly sampled from the population of interest \n",
    "- the data variables follow a normal distribution\n",
    "- a reasonably large sample size is used. \n",
    "- homogeneity of variance, i.e., the standard deviations of samples are approximately equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pylab as py\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats as sm_stats\n",
    "import statsmodels.stats.api as sms\n",
    "import scipy.stats as stats\n",
    "from numpy.random import seed\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import var\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Normality Checks\n",
    "**A large fraction of the field of statistics is concerned with data that assumes that it was drawn from a Gaussian distribution (also called normal distribution).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = np.random.normal(0, 1, 100)\n",
    "\n",
    "df = pd.DataFrame(data_points)\n",
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df, bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "sm.qqplot(data_points, line='45')\n",
    "py.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q-Q plot interpretation**\n",
    "<img src=\"https://i.stack.imgur.com/ZXRkL.png\" />\n",
    "URL: https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Shapiro-Wilk test of normality\n",
    "**The Shapiro-Wilk test tests the null hypothesis $H_0$ that the data was drawn from a normal distribution. The chance of rejecting the null hypothesis $H_0$ when it is true is close to 5% regardless of sample size.**\n",
    "\n",
    "URL https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "x = stats.norm.rvs(loc=5, scale=3, size=100)\n",
    "# x = stats.norm.rvs(loc=5, scale=3, size=1000)\n",
    "sns.distplot(x, bins=10)\n",
    "\n",
    "shapiro_test = shapiro(x)\n",
    "print(shapiro_test)\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if shapiro_test.pvalue > alpha:\n",
    "    print('Normal distribution (fail to reject H0)')\n",
    "else:\n",
    "    print('Another distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Statistical hypothesis testing\n",
    "\n",
    "**Do normality checks before hypothesis testing**\n",
    "- Histogram\n",
    "- Distribution plot\n",
    "- Q-Q plot\n",
    "- Shapiro-Wilkov Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Levene test - Variance test\n",
    "\n",
    "**Hypothesis**\n",
    "- $H_0$: all input samples are from populations with equal variances \n",
    "- **Fail to Reject $H_0$**: Equal variances \n",
    "- **Reject $H_0$**: Another variances\n",
    "\n",
    "URL https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.levene.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "a = [8.88, 9.12, 9.04, 8.98, 9.00, 9.08, 9.01, 8.85, 9.06, 8.99]\n",
    "b = [8.88, 8.95, 9.29, 9.44, 9.15, 9.58, 8.36, 9.18, 8.67, 9.05]\n",
    "c = [8.95, 9.12, 8.95, 8.85, 9.03, 8.84, 9.07, 8.98, 8.86, 8.98]\n",
    "\n",
    "# calculate variances\n",
    "[np.var(x, ddof=1) for x in [a, b, c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levene_test = levene(a, b, c)\n",
    "print(levene_test)\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if levene_test.pvalue > alpha:\n",
    "    print('Equal variances (fail to reject H0)')\n",
    "else:\n",
    "    print('Another variances (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The small p-value < 0.05 suggests that the populations do not have equal variances.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Student’s T-test\n",
    "\n",
    "## $t = \\frac{\\mu_1 - \\mu_2}{s_p \\sqrt{\\frac{1}{n_1} - \\frac{1}{n_2}}}$ \n",
    "\n",
    "## $s_p = \\sqrt{\\frac{(n_1 - 1) s^2_{X_1} + (n_2 - 1) s^2_{X_2}}{n_1 + n_2  - 2}}$\n",
    "\n",
    "**Hypothesis**\n",
    "- $H_0$: the means of two populations are equal \n",
    "- **Fail to Reject $H_0$**: No difference between the sample means \n",
    "- **Reject $H_0$**: Some difference between the sample means\n",
    "\n",
    "URL https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "seed(1)\n",
    "# data1 = 5 * randn(100) + 50\n",
    "# data2 = 5 * randn(100) + 51\n",
    "\n",
    "data1 = stats.norm.rvs(loc=5, scale=10, size=500)\n",
    "data2 = stats.norm.rvs(loc=5, scale=10, size=500)\n",
    "\n",
    "sns.distplot(data1, bins=10)\n",
    "sns.distplot(data2, bins=10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = ttest_ind(data1, data2)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Analysis of Variance (ANOVA)\n",
    "The same purpose as the T-Test but for more data samples.\n",
    "\n",
    "**Hypothesis**\n",
    "- $H_0$ = the mean across two or more groups are equal \n",
    "- **Fail to Reject $H_0$**: All sample distributions are equal \n",
    "- **Reject $H_0$**: One or more sample distributions are not equal\n",
    "\n",
    "URL https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "seed(1)\n",
    "alpha = 0.05\n",
    "\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "data3 = 5 * randn(100) + 52\n",
    "sns.distplot(data1, bins=10)\n",
    "sns.distplot(data2, bins=10)\n",
    "sns.distplot(data3, bins=10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = f_oneway(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Mann-Whitney U test\n",
    "\n",
    "Similar to T-test, but non-parametric for at least 20 observations in each data sample.\n",
    "\n",
    "**Hypothesis**\n",
    "- $H_0$ = no difference between the distributions of the data samples \n",
    "- **Fail to Reject $H_0$**: Sample distributions are equal \n",
    "- **Reject $H_0$**: Sample distributions are not equal\n",
    "\n",
    "URL https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "seed(1)\n",
    "data1 = 10 * rand(100) + 50\n",
    "data2 = 10 * rand(100) + 51\n",
    "sns.distplot(data1, bins=10)\n",
    "sns.distplot(data2, bins=10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(data1, data2) \n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distribution (fail to reject H0)') \n",
    "else:\n",
    "    print('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Kruskal-Wallis H Test\n",
    "\n",
    "The Kruskal-Wallis test is a nonparametric version of the one-way analysis of variance test or ANOVA for short. This test can be used to determine whether more than two independent samples have a different distribution. It can be thought of as the generalization of the Mann-Whitney U test.\n",
    "\n",
    "**Hypothesis**\n",
    "- $H_0$ = all data samples were drawn from the same distribution \n",
    "- **Fail to Reject $H_0$**: All sample distributions are equal \n",
    "- **Reject $H_0$**: One or more sample distributions are not equal.\n",
    "\n",
    "URL https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "seed(1)\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "data3 = 5 * randn(100) + 52\n",
    "sns.distplot(data1, bins=10)\n",
    "sns.distplot(data2, bins=10)\n",
    "sns.distplot(data3, bins=10)\n",
    "\n",
    "# compare samples\n",
    "stat, p = kruskal(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "    print('Same distributions (fail to reject H0)')\n",
    "else:\n",
    "    print('Different distributions (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Statistical power analysis\n",
    "\n",
    "## 3.1 Pearson's correlation between two samples\n",
    "\n",
    "## $r_{xy} = \\frac{ \\sum_{i=1}^{n}(x_i-\\bar{x})(y_i-\\bar{y}) }{%\n",
    "        \\sqrt{\\sum_{i=1}^{n}(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}}$\n",
    "\n",
    "**Correlation**\n",
    "- value in the range **<-1, 1>**\n",
    "- **Positive** correlation: both variables change in the same direction.\n",
    "- **Neutral** correlation: no relationship in the change of the variables. \n",
    "- **Negative** correlation: variables change in opposite directions.\n",
    "\n",
    "URL https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "seed(1)\n",
    "data1 = 10 * randn(10000) + 50\n",
    "data2 = data1 + (10 * randn(10000) + 50)\n",
    "\n",
    "# plotting\n",
    "# plt.plot(data1)\n",
    "# plt.plot(data2)\n",
    "sns.distplot(data1, bins=10)\n",
    "sns.distplot(data2, bins=10)\n",
    "\n",
    "# calculate pearson's correlation\n",
    "corr, _ = pearsonr(data1, data2) \n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Covariance\n",
    "\n",
    "Covariance provides the a measure of strength of correlation between two variable or more set of variables. The covariance matrix element $C_{ij}$ is the covariance of $x_i$ and $x_j$. The element $C_{ii}$ is the variance of $x_i$.\n",
    "- If $cov(x_i, x_j) = 0$ then variables are uncorrelated\n",
    "- If $cov(x_i, x_j) > 0$ then variables positively correlated\n",
    "- If $cov(x_i, x_j) < 0$ then variables negatively correlated\n",
    "\n",
    "$ np.cov(a,b) =\n",
    "    \\begin{bmatrix} \n",
    "        cov(a,a) & cov(a,b) \\\\\n",
    "        cov(a,b) & cov(b,b) \\\\\n",
    "    \\end{bmatrix}\n",
    "\\quad\n",
    "$\n",
    "\n",
    "URL https://numpy.org/doc/stable/reference/generated/numpy.cov.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import cov\n",
    "\n",
    "seed(1)\n",
    "data1 = 20 * randn(1000) + 100\n",
    "data2 = data1 + (10 * randn(1000) + 50)\n",
    "\n",
    "# plotting\n",
    "sns.distplot(data1, bins=10)\n",
    "sns.distplot(data2, bins=10)\n",
    "\n",
    "# calculate covariance matrix\n",
    "covariance = cov(data1, data2)[0, 1]\n",
    "print(covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Effect size by Cohen's d\n",
    "\n",
    "## $d = \\frac{\\mu_1 - \\mu_2}{s}$\n",
    "\n",
    "using pooled standard deviation $s$ and variance $s^2$\n",
    "## $s = \\sqrt{\\frac{(n_1 - 1) s^2_{X_1} + (n_2 - 1) s^2_{X_2}}{n_1 + n_2  - 2}}$\n",
    "\n",
    "Cohen’s $d$ measures the difference between the mean from two Gaussian-distributed variables. \n",
    "Because the score is standardized, there is a table for the interpretation of the result, summarized as\n",
    "- Small effect: d=0.20\n",
    "- Medium effect: d=0.50 \n",
    "- **Large effect: d=0.80**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cohen's d for independent samples\n",
    "def cohend(d1, d2):\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2) \n",
    "    \n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = var(d1, ddof=1), var(d2, ddof=1)\n",
    "\n",
    "    # calculate the pooled standard deviation\n",
    "    s = sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2)) \n",
    "    \n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = mean(d1), mean(d2)\n",
    "    \n",
    "    # calculate the effect size\n",
    "    d = (u1 - u2) / s \n",
    "    return d\n",
    "\n",
    "# generate two samples\n",
    "seed(1)\n",
    "data1 = 5 * randn(100) + 52\n",
    "data2 = 5 * randn(100) + 50\n",
    "\n",
    "# data1 = stats.norm.rvs(loc=5, scale=10, size=500)\n",
    "# data2 = stats.norm.rvs(loc=5, scale=10, size=500)\n",
    "\n",
    "# plt.plot(data1)\n",
    "# plt.plot(data2)\n",
    "sns.distplot(data1, bins=10)\n",
    "sns.distplot(data2, bins=10)\n",
    "\n",
    "cd = cohend(data1, data2)\n",
    "print('Cohens d value: %f' % cd)\n",
    "\n",
    "# interpret\n",
    "if 0.2 <= cd < 0.5:\n",
    "    print('Small effect - Cohens d value: %f' % cd)\n",
    "elif 0.5 <= cd < 0.8:\n",
    "    print('Medium effect - Cohens d value: %f' % cd)\n",
    "elif 0.8 <= cd:\n",
    "    print('Large effect - Cohens d value: %f' % cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Confidence interval\n",
    "\n",
    "### if (n >= 30) then $\\mu \\pm z \\frac{\\sigma}{\\sqrt{n}}$\n",
    "\n",
    "### if (n < 30)  then $\\mu \\pm t \\frac{\\sigma}{\\sqrt{n}}$\n",
    "\n",
    "- Sample size $n$\n",
    "- Mean $\\mu$\n",
    "- Standard deviation $\\sigma$\n",
    "- Degrees of Freedom in a sample $df=n-1$\n",
    "- The z-value for 95% confidence is $Z=1.96$\n",
    "- Z-table https://www.statisticshowto.com/tables/z-table/    \n",
    "- t-table  https://www.statisticshowto.com/tables/t-distribution-table/\n",
    "\n",
    "URL https://www.statsmodels.org/devel/generated/statsmodels.stats.weightstats.DescrStatsW.tconfint_mean.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "\n",
    "print('data1: confidence interval', sms.DescrStatsW(data1).tconfint_mean())\n",
    "print('data2: confidence interval', sms.DescrStatsW(data2).tconfint_mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinated example of generated datasets\n",
    "\n",
    "**Populations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1 = 80\n",
    "mean2 = 78\n",
    "size = 5\n",
    "data1 = stats.norm(mean1, size)\n",
    "data2 = stats.norm(mean2, size)\n",
    "\n",
    "start = 60\n",
    "stop = 100\n",
    "num = 1000\n",
    "x = np.linspace(start, stop, num)\n",
    "plt.plot(x, data1.pdf(x), 'b')\n",
    "plt.plot(x, data2.pdf(x), 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "sample1 = data1.rvs(sample_size)\n",
    "sample2 = data2.rvs(sample_size)\n",
    "print('sample1 mean=', sample1.mean())\n",
    "print('sample2 mean=', sample2.mean())\n",
    "sns.distplot(sample1, bins=5)\n",
    "sns.distplot(sample2, bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test of normality: if samples have nornal distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shapiro sample1:', stats.shapiro(sample1))\n",
    "print('Shapiro sample2:', stats.shapiro(sample1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test of variances: if samples are from populations with equal variances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(sample1, sample2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statistical power**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = cohend(sample1, sample2)\n",
    "print('Cohens d value: %f' % cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimate optimal sample size based on the Cohen's d value**\n",
    "- solve for any one parameter of the power of a two sample t-test\n",
    "- for t-test the keywords are: effect_size, nobs1, alpha, power, ratio\n",
    "- exactly one needs to be None, all others need numeric values\n",
    "\n",
    "URL https://www.statsmodels.org/stable/generated/statsmodels.stats.power.tt_ind_solve_power.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_stats.power.tt_ind_solve_power(cd, None, 0.05, 0.8, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two-sided confidence interval for weighted mean of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sample1: confidence interval', sms.DescrStatsW(sample1).tconfint_mean())\n",
    "print('sample2: confidence interval', sms.DescrStatsW(sample2).tconfint_mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment toward reality ;)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'observation': np.repeat([True, False], sample_size), \n",
    "                   'score': np.concatenate((sample1, sample2))})\n",
    "sns.boxplot('observation', 'score', data=df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
