{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Spark with jupyter notebook\n",
    "\n",
    "URL https://www.javacodemonk.com/installing-pyspark-with-jupyter-notebook-on-ubuntu-18-04-lts-31cd3781\n",
    "\n",
    "**Install pyspark**\n",
    "```\n",
    "$iau> pip install pyspark\n",
    "```\n",
    "\n",
    "**Configure environment using Bash profile**\n",
    "```\n",
    "~/.bashrc\n",
    "export SPARK_HOME=/home/<username>/<path-to-your-venv>/site-packages/pyspark/\n",
    "export PYSPARK_DRIVER_PYTHON=jupyter\n",
    "export PYSPARK_DRIVER_PYTHON_OPTS='notebook'\n",
    "```\n",
    "\n",
    "**Reload**\n",
    "```\n",
    "$ source ~/.bashrc\n",
    "```\n",
    "\n",
    "**Start Jupyter notebook from command line with pyspark**\n",
    "```\n",
    "pyspark\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Pi value with Monte Carlo simulation using Spark\n",
    "\n",
    "Based on https://docs.cloudera.com/machine-learning/cloud/spark/topics/ml-example--montecarlo-estimation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating $\\pi$\n",
    "# This PySpark example shows you how to estimate $\\pi$ in parallel\n",
    "# using Monte Carlo integration.\n",
    "\n",
    "import sys\n",
    "from random import random\n",
    "from operator import add\n",
    "\n",
    "import findspark\n",
    "findspark.find()\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"PythonPi\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(sys.argv)\n",
    "partitions = int(sys.argv[1]) if len(sys.argv) > 3 else 2\n",
    "\n",
    "# Change this number to other values, e.g., 10000, 100000 or more to see better PI value.\n",
    "# Be aware of computational power and runtime !!!\n",
    "n = 5000 * partitions\n",
    "\n",
    "def f(_):\n",
    "    x = random() * 2 - 1\n",
    "    y = random() * 2 - 1\n",
    "    return 1 if x ** 2 + y ** 2 < 1 else 0\n",
    "\n",
    "# To access the associated SparkContext\n",
    "count = spark.sparkContext.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\n",
    "print(\"Pi is roughly %f\" % (4.0 * count / n))\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
